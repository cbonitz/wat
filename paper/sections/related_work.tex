\section{Related Work}\seclabel{RelatedWork}
% \jmh{Adrian Colyer did a week on distributed tracing back in 10/6/2015. See https://blog.acolyer.org/2015/10/page/2/}
%
% \jmh{Would be good to give a nod to Bailis' SoCC paper and also the refs in it on explicit causality~\cite{bailis2012potential}}

\paragraph{Data Provenance}
When discussing data provenance, we have focused primarily on \whyprovenance{},
as \watprovenance{} is a generalization of \whyprovenance{}. However, there are
other forms of data provenance. \Whyprovenance{}~\cite{green2007provenance}
formalizes not only why a particular output is produced by a relational query,
but also how. \whereprovenance{}~\cite{buneman2001and} formalizes the set of
input \emph{attributes} that contribute to an output \emph{attribute}.
%
In \cite{cui2003lineage}, Cui et al.\ provide algorithms for computing the
provenance of more generic data transformation operators that satisfy certain
properties (e.g., homomorphisms, aggregators). In
\cite{woodruff1997supporting}, Woodruff et al.\ use weak inverse functions to
compute the provenance of generic operators.
%
Why-, how-, and \whereprovenance{} are all limited to the domain of relational
queries, and all five forms of provenance are limited to the domain of data
transformations applied to static data. \Watprovenance{} is applicable to state
machines with state that varies over time.

\paragraph{Black Box Provenance}
RDataTracker \cite{lerner2014collecting}, noWorkflow
\cite{murta2014noworkflow}, and SPADE \cite{gehani2012spade} are frameworks
that attempt to record the provenance of data through an \emph{arbitrary} black
box using general purpose low-level provenance tracing techniques. RDataTracker
and noWorkflow use reflection and runtime information to track the provenance
of data through minimally annotated R and Python scripts. SPADE collects
provenance information from operating system audit logs, network artifacts,
LLVM instrumented applications, and applications dynamically instrumented for
taint analysis. The benefit of these frameworks is their generality. However,
their generality comes at the cost of verbosity. These provenance frameworks
produce a large amount of low-level implementation-specific provenance
information that can be challenging to interpret.

\paragraph{Data-Dependent Process Provenance}
A data-dependent process (DDP) is a finite state machine that evaluates queries
against a relational database to determine some transitions and uses external
requests to trigger other transitions~\cite{deutch2014provenance,
deutch2015provenance}. In \cite{deutch2014provenance} and
\cite{deutch2015provenance}, Deutch et al.\ extend provenance
semirings~\cite{green2007provenance} to linear temporal logic formulas issued
against a DDP.
%
Both DDP provenance and \watprovenance{} aim to extend traditional data
provenance to state machines, but they do so in very different ways. DDP
provenance is used to explain how particular execution traces may arise.
%
% For example, DDP provenance might inform us about the database contents under
% which a particular state in the DDP can be reached.
%
\Watprovenance{}, on the other hand, aims to explain why a state machine
generates a particular output with respect to a fixed trace of inputs.
% DDPs are also assumed to be finite and backed by relational databases, while
% \watprovenance{} targets arbitrary (even infinite) deterministic state
% machines.

\paragraph{Network Provenance}
Network provenance was originally introduced in~\cite{zhou2010efficient} as a
generalization of data provenance to programs written in the extended
relational language NDLog~\cite{loo2006design}. ExSPAN~\cite{zhou2010efficient}
and DistTape~\cite{zhou2012distributed} are two accompanying implementations
that record the network provenance of a distributed system implemented in
NDLog.
%
The network provenance of a piece of data is tied to the particular NDLog
program that created it, whereas \watprovenance{} is defined with respect to
abstract state machines instead of concrete implementations. As a result,
network provenance provides finer grained debugging information than
\watprovenance{}, but is applicable only to systems written in NDLog.
\Watprovenance{} provides coarser grained debugging information, but is
applicable to arbitrary state machines.

\paragraph{Scientific Workflow Systems}
Scientific workflow systems like Taverna \cite{wolstencroft2013taverna}, Kepler
\cite{altintas2006provenance}, Pegasus \cite{kim2008provenance}, and Swift
\cite{wozniak2013swift} can be used to structure complex computational tasks as
a graph, composing tasks by connecting the outputs of one task to the inputs of
another. These systems are limited to the workflow languages that they support,
and these languages are not typically used to build distributed systems. They
also assume that the inputs to a workflow are static. \Watprovenance{}
formalizes provenance for arbitrary distributed systems composed of
time-varying state machines.

\paragraph{DISC Provenance}
Data intensive scalable computing (DISC) frameworks like Apache
Hadoop~\cite{shvachko2010hadoop} and Apache Spark~\cite{zaharia2010spark} can
execute data-parallel programs on massive amounts of data both efficiently and
with fault tolerance. Work on GMRW provenance~\cite{ikeda2011provenance} and
systems like BigDebug~\cite{gulzar2016bigdebug},
Titian~\cite{interlandi2015titian}, RAMP~\cite{park2011ramp}, and
Newt~\cite{logothetis2013scalable} augment DISC frameworks with data
provenance.
%
Unlike \watprovenance{}, DISC provenance is restricted to the domain of data
intensive computations over static data and cannot be applied to other
distributed systems components like storage systems, coordination services,
load balancers, etc.
%
DISC provenance frameworks take advantage of operator interfaces (e.g., map,
filter, aggregate) to construct lineage of arbitrary operator implementations
similar to how \watprovenance{} specifications are written against high-level
interfaces instead of implementations.


\paragraph{Distributed Tracing Tools}
Distributed tracing tools like Dapper~\cite{sigelman2010dapper},
X-trace~\cite{fonseca2007x}, Magpie~\cite{barham2003magpie},
Stardust~\cite{thereska2006stardust}, and lprof~\cite{zhao2014lprof} allow
programmers to trace messages through large and complex distributed systems
that span multiple nodes and administrative domains.
% These traces enable programmers to answer many useful debugging questions
% (e.g.\ ``When a client issues a request, which nodes are contacted before a
% reply is returned?'').
The fundamental distinction between distributed traces and \watprovenance{} is
that distributed traces do not carry historical information that link prior
inputs to present outputs. For example, traces may show you which clients
contacted a key-value store and when, but they will not show you which requests
wrote the values that later requests read back.
%
Also note that lprof, unlike other tracing tools, constructs traces by
analyzing systems' existing logs. In the future, we plan to explore whether we
can use a similar technique to construct traces.
